{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://visitseattle.org/things-to-do/events/', 'https://visitseattle.org/things-to-do/events/', 'https://visitseattle.org/things-to-do/events/festivals/', 'https://visitseattle.org/things-to-do/events/submit-your-event/', '/?s=&frm=events', 'https://visitseattle.org/events/an-evening-with-lucia-micarelli/', 'https://visitseattle.org/events/an-evening-with-lucia-micarelli/', 'https://visitseattle.org/events/dylan-leblanc/', 'https://visitseattle.org/events/dylan-leblanc/']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_event_urls(page_url):\n",
    "    response = requests.get(page_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Extracting event detail page URLs\n",
    "    event_urls = [a['href'] for a in soup.find_all('a', href=True) if 'events' in a['href']]\n",
    "    \n",
    "    return event_urls\n",
    "\n",
    "# Example usage\n",
    "page_url = 'https://visitseattle.org/events/page/1'\n",
    "event_urls = fetch_event_urls(page_url)\n",
    "print(event_urls[:9])  # Print the first 9 URLs to verify\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total URLs scraped: 1336\n"
     ]
    }
   ],
   "source": [
    "def scrape_all_event_urls(base_url, start_page=1, end_page=41):\n",
    "    all_event_urls = []\n",
    "    for page in range(start_page, end_page + 1):\n",
    "        page_url = f\"{base_url}page/{page}\"\n",
    "        event_urls = fetch_event_urls(page_url)\n",
    "        all_event_urls.extend(event_urls)\n",
    "        # print(f\"Scraped {len(event_urls)} URLs from {page_url}\")\n",
    "    \n",
    "    return all_event_urls\n",
    "\n",
    "# Base URL for pagination\n",
    "base_url = 'https://visitseattle.org/events/'\n",
    "all_event_urls = scrape_all_event_urls(base_url)\n",
    "print(f\"Total URLs scraped: {len(all_event_urls)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_event_details(url):\n",
    "    if not url.startswith('http'):\n",
    "        url = 'https://visitseattle.org' + url\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    name = soup.find('h1').get_text(strip=True) if soup.find('h1') else 'N/A'\n",
    "    \n",
    "    # Example of adjusting based on actual page structure; these will need to be customized\n",
    "    date_element = soup.find(class_='event-date')\n",
    "    date = date_element.get_text(strip=True) if date_element else 'N/A'\n",
    "    \n",
    "    location_element = soup.find(class_='event-location')\n",
    "    location = location_element.get_text(strip=True) if location_element else 'N/A'\n",
    "    \n",
    "    event_type_element = soup.find(class_='event-type')\n",
    "    event_type = event_type_element.get_text(strip=True) if event_type_element else 'N/A'\n",
    "    \n",
    "    region_element = soup.find(class_='event-region')\n",
    "    region = region_element.get_text(strip=True) if region_element else 'N/A'\n",
    "    \n",
    "    return {\n",
    "        'Name': name,\n",
    "        'Date': date,\n",
    "        'Location': location,\n",
    "        'Type': event_type,\n",
    "        'Region': region\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to events.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compile_events_to_csv(event_urls, csv_filename):\n",
    "    events_data = [fetch_event_details(url) for url in event_urls]\n",
    "    \n",
    "    # Convert list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(events_data)\n",
    "    \n",
    "    # Save DataFrame to CSV\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Data saved to {csv_filename}\")\n",
    "\n",
    "# Compile and save data\n",
    "csv_filename = 'events.csv'\n",
    "compile_events_to_csv(all_event_urls[:9], csv_filename)  # Limiting to first 9 for demonstration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def lookup_location_coordinates(location):\n",
    "    nominatim_url = \"https://nominatim.openstreetmap.org/search\"\n",
    "    params = {\n",
    "        'q': location,\n",
    "        'format': 'json',\n",
    "        'limit': 1\n",
    "    }\n",
    "    response = requests.get(nominatim_url, params=params)\n",
    "    data = response.json()\n",
    "    if data:\n",
    "        latitude = data[0]['lat']\n",
    "        longitude = data[0]['lon']\n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def lookup_location_coordinates(location):\n",
    "    nominatim_url = \"https://nominatim.openstreetmap.org/search\"\n",
    "    params = {\n",
    "        'q': location,\n",
    "        'format': 'json',\n",
    "        'limit': 1\n",
    "    }\n",
    "    response = requests.get(nominatim_url, params=params)\n",
    "    data = response.json()\n",
    "    if data:\n",
    "        latitude = data[0]['lat']\n",
    "        longitude = data[0]['lon']\n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        return None, None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
